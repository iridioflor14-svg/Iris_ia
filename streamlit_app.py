# Arquivo: streamlit_app.py

import streamlit as st
import random
import numpy as np
import pickle
import os
import tensorflow as tf

# --- Configura√ß√£o da P√°gina ---
st.set_page_config(
    page_title="IA IRIS: Intelig√™ncia Emocional e Criativa",
    page_icon="ü§ñ",
    layout="wide"
)

# Nomes dos arquivos de Deep Learning (DEVEM ser iguais aos que voc√™ subiu no GitHub)
MODELO_ARQUIVO = 'modelo_sentimento.h5'
TOKENIZER_ARQUIVO = 'tokenizer.pkl'
MAX_LEN = 50 # O comprimento m√°ximo da sequ√™ncia usada no treinamento


# --- 1. Fun√ß√µes de Carregamento de Modelo (COM CACHE) ---

@st.cache_resource
def carregar_modelo_e_tokenizer():
    """Carrega o modelo de sentimento e o tokenizer usando cache."""
    try:
        # Carrega o modelo
        model = tf.keras.models.load_model(MODELO_ARQUIVO)

        # Carrega o tokenizer (o dicion√°rio para converter palavras em n√∫meros)
        with open(TOKENIZER_ARQUIVO, 'rb') as f:
            tokenizer = pickle.load(f)

        st.success("‚úÖ Modelo de Deep Learning carregado com sucesso!")
        return model, tokenizer, True
    
    except Exception as e:
        # Em caso de falha (arquivos ausentes ou erro), volta para o modo simula√ß√£o.
        st.warning(f"‚ö†Ô∏è Erro ao carregar modelo ({MODELO_ARQUIVO} ou {TOKENIZER_ARQUIVO} n√£o encontrado/inv√°lido). Usando simula√ß√£o. Erro: {e}")
        return None, None, False


# --- 2. Fun√ß√µes de An√°lise de Sentimento ---

def analisar_sentimento_real(frase, modelo, tokenizer):
    """Analisa o sentimento de uma frase usando o modelo de Deep Learning treinado."""
    
    # Pr√©-processamento: Converter texto para n√∫meros (usando o tokenizer carregado)
    sequence = tokenizer.texts_to_sequences([frase])
    
    # Padroniza√ß√£o: Garantir que a sequ√™ncia tenha o tamanho correto
    padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(
        sequence, 
        maxlen=MAX_LEN, 
        padding='post', 
        truncating='post'
    )
    
    # Previs√£o: O modelo retorna um n√∫mero entre 0 e 1 (probabilidade)
    probabilidade = modelo.predict(padded_sequence)[0][0]
    
    # A IA IRIS est√° treinada para:
    # Perto de 1.0 = Positivo
    # Perto de 0.0 = Negativo
    
    return probabilidade


def simular_analise(frase):
    """Simula uma an√°lise de sentimento (usada quando o modelo n√£o √© carregado)."""
    
    # Simula uma pontua√ß√£o (P) entre 0.0 e 1.0
    P = random.uniform(0.1, 0.9)
    
    # Simula uma resposta baseada na simula√ß√£o
    if P > 0.65:
        emocao = "Satisfa√ß√£o/Calma"
        resposta = "Sinto satisfa√ß√£o e calma. O resultado √© positivo."
        imagem = "Um lago tranquilo ao amanhecer, com n√©voa suave. Imagem."
    elif P < 0.35:
        emocao = "Desconforto/Tens√£o"
        resposta = "Detecto um forte desconforto. O resultado √© negativo."
        imagem = "Uma tempestade que se aproxima em um deserto. Imagem."
    else:
        emocao = "Ambiguidade/Neutro"
        resposta = "Estou confusa. O sentimento √© amb√≠guo."
        imagem = "Uma interroga√ß√£o gigante flutuando em um nevoeiro cinzento. Imagem."
        
    return P, emocao, resposta, imagem


def fazer_analise_e_resposta(frase, modelo, tokenizer, modelo_carregado):
    """Decide se usa o modelo real ou a simula√ß√£o e formata a sa√≠da."""
    
    if modelo_carregado:
        # Usa o modelo de Deep Learning real!
        P_real = analisar_sentimento_real(frase, modelo, tokenizer)
        
        # Traduz a pontua√ß√£o do modelo real (P_real) em uma resposta para a IRIS
        if P_real > 0.7:
            emocao = "Felicidade/Satisfa√ß√£o"
            resposta = "Detecto uma forte **emo√ß√£o positiva**! Meu sentimento √© de satisfa√ß√£o."
            imagem = "Um campo de flores sob o sol. Imagem."
        elif P_real < 0.3:
            emocao = "Tristeza/Tens√£o"
            resposta = "Sinto uma **emo√ß√£o negativa** clara. Detecto um sentimento de tens√£o ou tristeza."
            imagem = "O reflexo de uma l√°grima em uma po√ßa. Imagem."
        else:
            emocao = "Neutro/Ambiguidade"
            resposta = "O sentimento √© **neutro ou amb√≠guo**. N√£o consigo classificar a emo√ß√£o de forma clara."
            imagem = "Uma parede branca e lisa. Imagem."
            
        P = P_real
        return P, emocao, resposta, imagem
    
    else:
        # Usa a simula√ß√£o (se o modelo real falhar)
        return simular_analise(frase)


# --- 3. Fun√ß√£o de Busca e Tradu√ß√£o (Simuladas) ---

def simular_busca_e_traducao(frase, resultado_sentimento):
    """Simula a busca na web e a tradu√ß√£o."""
    
    # 3.1 Simula√ß√£o de Busca
    # Se a frase for complexa, a IA IRIS tentaria uma busca.
    if len(frase.split()) > 5:
        st.info("üåê A IA IRIS iniciaria uma busca na web com a frase...")
    
    # 3.2 Simula√ß√£o de Tradu√ß√£o
    # A tradu√ß√£o (Ingl√™s) est√° ativa apenas para demonstra√ß√£o.
    traducao = f"The translation service is active but running in a simulated mode for this response type."
    
    return traducao


# --- 4. Interface Principal do Streamlit ---

def main():
    
    st.title("IA IRIS: Intelig√™ncia Emocional e Criativa ü§ñ")
    st.markdown("---")
    
    # Carrega o modelo de sentimento e o tokenizer uma √∫nica vez
    modelo, tokenizer, modelo_carregado = carregar_modelo_e_tokenizer()

    st.markdown("Diga √† Iris para 'escrever um poema', 'quem √© o criador', ou apenas uma frase (ex: 'Sinto-me muito feliz hoje').")

    # √Årea de entrada de texto
    frase_usuario = st.text_input("Sua Frase para a IA Iris:", value="Qual seu nome?")

    # Bot√£o de A√ß√£o (√∫nico bot√£o para todas as a√ß√µes)
    if st.button("Analisar Sentimento, Fazer Busca e Traduzir", type="primary"):
        
        if not frase_usuario.strip():
            st.warning("Por favor, digite uma frase para a IA Iris analisar.")
            return

        # --- Execu√ß√£o da An√°lise de Sentimento (Real ou Simulado) ---
        
        # Retorna P (pontua√ß√£o), emo√ß√£o, resposta_iris e imagem_desc
        P, emocao, resposta_iris, imagem_desc = fazer_analise_e_resposta(
            frase_usuario, modelo, tokenizer, modelo_carregado
        )

        st.markdown("---")
        st.subheader("üëÅÔ∏è Resultado da An√°lise da IA Iris:")

        # Exibi√ß√£o do Resultado
        col1, col2 = st.columns([1, 2])
        
        with col1:
            st.metric(label="Pontua√ß√£o P (Probabilidade)", value=f"{P:.2f}")

        with col2:
            st.write(f"**{emocao}:** {resposta_iris} (P: {P:.2f})")
            st.write(f"**Express√£o Visual:** {imagem_desc}")
            
        # --- Execu√ß√£o da Busca e Tradu√ß√£o (Simuladas) ---
        traducao = simular_busca_e_traducao(frase_usuario, resposta_iris)

        st.markdown("---")
        st.subheader("üìö Tradu√ß√£o (Ingl√™s):")
        st.info(traducao)

        # Mensagem de Sucesso no Final
        if modelo_carregado:
            st.success("‚úÖ A IA IRIS demonstrou todo seu potencial de Deep Learning real, busca na web e tradu√ß√£o!")
        else:
            st.success("‚úÖ A IA IRIS demonstrou todo seu potencial de ML (simulado), busca na web e tradu√ß√£o!")

if __name__ == "__main__":
    main()
